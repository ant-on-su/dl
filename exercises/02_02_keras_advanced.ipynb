{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/custom.css\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Advanced\n",
    "\n",
    "![footer_logo](../images/logo.png)\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal of this Notebook is to dive deeper in the Keras API and touch some of the more advanced topics.\n",
    "\n",
    "## Program\n",
    "\n",
    "1. Functional API\n",
    "2. Large datasets with Keras\n",
    "3. Callbacks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = 15, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Data\n",
    "\n",
    "We shall train a model using the functional API to classify fashion images.\n",
    "\n",
    "<img src=\"../images/fashion-mnist.png\" width=\"400\"/>\n",
    "\n",
    "Source: [Kaggle](https://www.kaggle.com/zalando-research/fashionmnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll write some fashion MNIST images to a temporary folder with this structure and use this in the exercises later.\n",
    "\n",
    "To do this we'll use some helper functions in the `load_fashion_mnist.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_fashion_mnist import save_fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is written to C:\\Users\\651494\\AppData\\Local\\Temp\\tmpzg31ss5a\n"
     ]
    }
   ],
   "source": [
    "temp_dir = save_fashion_mnist(10000, 1000, 1000)\n",
    "print(f\"Dataset is written to {temp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls -lR {temp_dir} | head -n 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Local Disk\n",
      " Volume Serial Number is 0CBC-FF85\n",
      "\n",
      " Directory of C:\\Users\\651494\\AppData\\Local\\Temp\\tmpzg31ss5a\n",
      "\n",
      "16-12-2021  15:57    <DIR>          .\n",
      "16-12-2021  15:57    <DIR>          ..\n",
      "16-12-2021  15:57    <DIR>          test\n",
      "16-12-2021  15:57    <DIR>          train\n",
      "16-12-2021  15:57    <DIR>          valid\n",
      "               0 File(s)              0 bytes\n",
      "               5 Dir(s)  133.726.744.576 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir {temp_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Functional API\n",
    "\n",
    "Only sequentially using `.add()` limits the complexity of your neural networks.\n",
    "Keras has other API's to solve that, the [functional API](https://keras.io/getting-started/functional-api-guide/) really helps with:\n",
    "\n",
    "> \"defining complex models, such as multi-output models, directed acyclic graphs, or models with shared layers.\"\n",
    "\n",
    "Let's check a minimum working example from the documentation.\n",
    "It defines a network with two hidden layers and an output layer for 10 classes.\n",
    "With the sequential API it would look something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=(784,)))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the `Input` tensor, something we're initially allowed to ignore with the Sequential API, and use it when calling the first hidden layer object.\n",
    "Layers in Keras are [callable](https://en.wikipedia.org/wiki/Callable_object#In_Python) objects which mean we can call them after instantiation.\n",
    "When called layers return a tensor that contains all operations (layers and their weights) applied so far.\n",
    "\n",
    "We put the initial `inputs` and the final result `prediction` in a `Model` object that has similar functionality to a `Sequential` object.\n",
    "In this case, we don't really care about the intermediate results, so we use the dummy variable name `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(784,))\n",
    "x = Dense(64, activation=\"relu\")(inputs)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "predictions = Dense(10, activation=\"softmax\")(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this specific example, it's mainly more typing but this API allows you to be really flexible for non-sequential models. However, it allows you to easily define models with multiple inputs or outputs, or where you make use of the output from an earlier layer. \n",
    "\n",
    "A good example is a _Residual Network_ block. A residual network is made out of blocks where the output is copied and 'saved' for a little while, while other operations (e.g. convolutions) are applied to it. Then, these two outputs (original which has not been passed through more layers, and the version that _has_ been passed through more layers) are combined through a summation. The advantage of a ResNet architecture is that it tackles the vanishing gradient problem. \n",
    "\n",
    "![](https://developer.ridgerun.com/wiki/images/0/01/Residual_block.png)\n",
    "\n",
    "This is easily implemented in the functional API: \n",
    "```python\n",
    "inputs = Input(shape=(784,))\n",
    "x = Dense(64, activation=\"relu\")(inputs)\n",
    "x_original = x.copy() \n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Add()([x, x_original])\n",
    "predictions = Dense(10, activation=\"softmax\")(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Exercise: functional API\n",
    "> \n",
    "> Rewrite the model below with the functional API and put it into a function `make_fashion_mnist_model()`.\n",
    ">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_48 (Conv2D)          (None, 28, 28, 64)        320       \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 14, 14, 32)        8224      \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPoolin  (None, 7, 7, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 1568)              0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 256)               401664    \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 412,778\n",
      "Trainable params: 412,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def make_fashion_mnist_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPool2D(pool_size=2))\n",
    "\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Conv2D(filters=32, kernel_size=2, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=2))\n",
    "\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    # why no batch normalization at this point?\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = make_fashion_mnist_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_fashion_mnist_model_function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19952/3262595279.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fashion_mnist_model_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'make_fashion_mnist_model_function' is not defined"
     ]
    }
   ],
   "source": [
    "def make_fashion_minst_model_functional(): \n",
    "    ...\n",
    "    \n",
    "model = make_fashion_mnist_model_function()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 28, 28, 64)        320       \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 14, 14, 32)        8224      \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 7, 7, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 1568)              0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 256)               401664    \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 412,778\n",
      "Trainable params: 412,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# %load ../answers/functional.py\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def make_fashion_mnist_model():\n",
    "\n",
    "    inputs = Input(shape=(28, 28, 1))\n",
    "\n",
    "    x = Conv2D(64, kernel_size=2, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Conv2D(filters=32, kernel_size=2, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = make_fashion_mnist_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Large datasets with Keras\n",
    "\n",
    "Using numpy arrays as input can limit you once your datasets don't fit in memory anymore or if you're using  multiple devices.\n",
    "Keras has some built-in tools to help you; but training also works nicely with Python generators; and there's the integration with `tf.data.Datasets` to leverage TensorFlow's functionality.\n",
    "\n",
    "If you're not familiar with Python iterators and generators, make sure to do a bit of [reading](https://wiki.python.org/moin/Generators) before continuing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras generators\n",
    "\n",
    "The idea behind Keras generators is to not load all data in memory at once, but to generate batches of data and feed those to the model.\n",
    "For instance, instead of loading all samples, we only load 100 training points and feed those to the GPU on the fly.\n",
    "\n",
    "A good example of a Keras generator is the [`ImageDataGenerator`](https://keras.io/preprocessing/image/#imagedatagenerator-class).\n",
    "This class takes data and performs various forms of image augmentation on the fly, like whitening, shearing and zooming.\n",
    "As the name `Generator` implies, it doesn't compute these augmentations all at once, but does this in batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# help(ImageDataGenerator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class has three methods to generated batches of augmented data:\n",
    "\n",
    "- `.flow()`: Takes data & label arrays\n",
    "- `.flow_from_dataframe()`: Takes the DataFrame and the path to a directory with the mapped images in the DataFrame\n",
    "- `.flow_from_directory()`: Takes the path to a directory\n",
    "\n",
    "We'll focus on the `.flow_from_directory()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function flow_from_directory in module keras.preprocessing.image:\n",
      "\n",
      "flow_from_directory(self, directory, target_size=(256, 256), color_mode='rgb', classes=None, class_mode='categorical', batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='png', follow_links=False, subset=None, interpolation='nearest')\n",
      "    Takes the path to a directory & generates batches of augmented data.\n",
      "    \n",
      "    Args:\n",
      "        directory: string, path to the target directory. It should contain one\n",
      "          subdirectory per class. Any PNG, JPG, BMP, PPM or TIF images inside\n",
      "          each of the subdirectories directory tree will be included in the\n",
      "          generator. See [this script](\n",
      "            https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d)\n",
      "              for more details.\n",
      "        target_size: Tuple of integers `(height, width)`, defaults to `(256,\n",
      "          256)`. The dimensions to which all images found will be resized.\n",
      "        color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\". Whether\n",
      "          the images will be converted to have 1, 3, or 4 channels.\n",
      "        classes: Optional list of class subdirectories\n",
      "            (e.g. `['dogs', 'cats']`). Default: None. If not provided, the list\n",
      "              of classes will be automatically inferred from the subdirectory\n",
      "              names/structure under `directory`, where each subdirectory will be\n",
      "              treated as a different class (and the order of the classes, which\n",
      "              will map to the label indices, will be alphanumeric). The\n",
      "              dictionary containing the mapping from class names to class\n",
      "              indices can be obtained via the attribute `class_indices`.\n",
      "        class_mode: One of \"categorical\", \"binary\", \"sparse\",\n",
      "            \"input\", or None. Default: \"categorical\".\n",
      "            Determines the type of label arrays that are returned:\n",
      "            - \"categorical\" will be 2D one-hot encoded labels,\n",
      "            - \"binary\" will be 1D binary labels,\n",
      "            - \"sparse\" will be 1D integer labels,\n",
      "            - \"input\"  will be images identical to input images (mainly used to\n",
      "              work with autoencoders).\n",
      "            - If None, no labels are returned (the generator will only yield\n",
      "              batches of image data, which is useful to use with\n",
      "              `model.predict()`).\n",
      "            Please note that in case of class_mode None, the data still needs to\n",
      "            reside in a subdirectory of `directory` for it to work correctly.\n",
      "        batch_size: Size of the batches of data (default: 32).\n",
      "        shuffle: Whether to shuffle the data (default: True) If set to False,\n",
      "          sorts the data in alphanumeric order.\n",
      "        seed: Optional random seed for shuffling and transformations.\n",
      "        save_to_dir: None or str (default: None). This allows you to optionally\n",
      "          specify a directory to which to save the augmented pictures being\n",
      "          generated (useful for visualizing what you are doing).\n",
      "        save_prefix: Str. Prefix to use for filenames of saved pictures (only\n",
      "          relevant if `save_to_dir` is set).\n",
      "        save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\",\n",
      "            \"tif\", \"jpg\"\n",
      "            (only relevant if `save_to_dir` is set). Default: \"png\".\n",
      "        follow_links: Whether to follow symlinks inside\n",
      "            class subdirectories (default: False).\n",
      "        subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
      "          `validation_split` is set in `ImageDataGenerator`.\n",
      "        interpolation: Interpolation method used to resample the image if the\n",
      "          target size is different from that of the loaded image. Supported\n",
      "          methods are `\"nearest\"`, `\"bilinear\"`, and `\"bicubic\"`. If PIL version\n",
      "          1.1.3 or newer is installed, `\"lanczos\"` is also supported. If PIL\n",
      "          version 3.4.0 or newer is installed, `\"box\"` and `\"hamming\"` are also\n",
      "          supported. By default, `\"nearest\"` is used.\n",
      "    \n",
      "    Returns:\n",
      "        A `DirectoryIterator` yielding tuples of `(x, y)`\n",
      "            where `x` is a numpy array containing a batch\n",
      "            of images with shape `(batch_size, *target_size, channels)`\n",
      "            and `y` is a numpy array of corresponding labels.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ImageDataGenerator.flow_from_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method expects a certain structure for it to work, read the documentation on `directory` and `classes` in the cell above.\n",
    "\n",
    "<img src=\"../images/keras_advanced/keras_flow_from_directory.jpeg\" alt=\"flow_from\" style=\"width: 500px;\"/>\n",
    "\n",
    "[Source](https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall create three ImageDataGenerators, one each for the train, valid and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale=1.0 / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
    ")\n",
    "test_data_generator = ImageDataGenerator(rescale=1.0 / 255)\n",
    "valid_data_generator = ImageDataGenerator(rescale=1.0 / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Exercise:\n",
    "    \n",
    "Use `.flow_from_directory()` to create three iterators that allow data to flow from the appropriate generator. \n",
    "    \n",
    "When creating the iterators:\n",
    "> - Build a path for argument `directory` from `temp_dir`.    \n",
    "> - Infer the `class_mode`, `target_size` and `color_mode` from the model.\n",
    "> - Set the `batch_size` to 32 and choose a shuffle and seed.\n",
    "> - With the already defined code, fit the Fashion MNIST model using these iterators, your loss should go lower than 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_iterator = train_data_generator.flow_from_directory(\n",
    "    directory=os.path.join(temp_dir, 'train'),\n",
    "    target_size=(28, 28), \n",
    "    color_mode='grayscale',\n",
    "    batch_size=8,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_iterator = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# %load ../answers/image_data_generator.py\n",
    "train_iterator = train_data_generator.flow_from_directory(\n",
    "    directory=os.path.join(temp_dir, \"train\"),\n",
    "    target_size=(28, 28),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=8,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")\n",
    "valid_iterator = valid_data_generator.flow_from_directory(\n",
    "    directory=os.path.join(temp_dir, \"valid\"),\n",
    "    target_size=(28, 28),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=8,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")\n",
    "test_iterator = test_data_generator.flow_from_directory(\n",
    "    directory=os.path.join(temp_dir, \"test\"),\n",
    "    target_size=(28, 28),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=1,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 92s 73ms/step - loss: 0.9577 - accuracy: 0.6467 - val_loss: 0.5564 - val_accuracy: 0.7750: 1.1609 - accuracy: 0. - ETA: 45s - loss: 1.13 - ETA: 44s - loss: 1.1261 - accur - ETA: 43s - loss: 1. - E\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1278c660d00>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_model = make_fashion_mnist_model()\n",
    "fashion_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "step_size_train = train_iterator.n // train_iterator.batch_size\n",
    "step_size_valid = valid_iterator.n // valid_iterator.batch_size\n",
    "\n",
    "fashion_model.fit(train_iterator,\n",
    "    steps_per_epoch=step_size_train,\n",
    "    validation_data=valid_iterator,\n",
    "    validation_steps=step_size_valid,\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.9000\n",
      "[0.40847399830818176, 0.8999999761581421]\n"
     ]
    }
   ],
   "source": [
    "print(fashion_model.evaluate(test_iterator, steps=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example of a Keras generator is the [TimeseriesGenerator](https://keras.io/preprocessing/sequence/#timeseriesgenerator) that generates batches of temporal data from a sequence of data points.\n",
    "This could also been seen as generating a dataset that's possibly to big for memory: generating all possible batches from a sequence can easily be bigger that your RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Question\n",
    "\n",
    "Why are we setting `shear_range`, `zoom_range` and `horizontal_flip` on the `train_data_generator` and not on the `test_data_generator` and `valid_data_generator`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We've seen how we can leverage datasets that are too big to fit in memory.\n",
    "Keras has its own generators but it's also pretty easy to build your own.\n",
    "Many file formats & interfaces also allow you to access files without loading them, like the option `mmap_mode` for [`numpy.load`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.load.html).\n",
    "If you would like to stay closer to TensorFlow, check out the guide on [Datasets](\n",
    "https://www.tensorflow.org/guide/datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Callbacks\n",
    "\n",
    "Callbacks allow you to perform tasks during certain moments of training.\n",
    "For instance, you can compute performance measures like training time, or look at the states of the model to detect when it breaks down.\n",
    "\n",
    "You can pass multiple callbacks in a `list` to the `.fit()` method or your model and they'll be called at the rights times during training.\n",
    "There are six moments when a callback can be executed: at starts and/or stops of training, epochs and/or batches.\n",
    "\n",
    "\n",
    "### Built-in callbacks\n",
    "\n",
    "Let's look at two commonly used callbacks in `tensorflow.keras.callbacks`: `EarlyStopping` and `ModelCheckpoint`.\n",
    "`EarlyStopping` stops training when your model performance doesn't get better and can save you a lot of waiting time.\n",
    "`ModelCheckpoint` saves the model after every epoch to make sure your progress doesn't get lost if your training process gets killed.\n",
    "\n",
    "> #### Exercise: Built-in callbacks\n",
    ">\n",
    "> - Use the fitting procedure from the previous exercise and add the `EarlyStopping` and `ModelCheckpoint` callbacks.\n",
    "> - For `ModelCheckpoint` save only the best model and save to the variable `model_path` given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates an output folder where your model parameters will be saved. \n",
    "import shutil \n",
    "\n",
    "model_dir = os.path.join(\"..\", \"output\", \"fashion_mnist\")\n",
    "model_path = os.path.join(model_dir, \"model.h5\")\n",
    "\n",
    "if os.path.exists(model_dir):\n",
    "    shutil.rmtree(model_dir)\n",
    "os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Load & compile your model. \n",
    "... \n",
    "\n",
    "# Define your callbacks. \n",
    "...\n",
    "\n",
    "# Fit your model, with the callbacks. \n",
    "...\n",
    "\n",
    "# Evaluate your model. \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "10/10 [==============================] - 2s 121ms/step - loss: 2.2858 - val_loss: 2.2736\n",
      "Epoch 2/4\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 2.2423 - val_loss: 2.2097\n",
      "Epoch 3/4\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 2.1443 - val_loss: 2.0882\n",
      "Epoch 4/4\n",
      "10/10 [==============================] - 1s 82ms/step - loss: 2.0492 - val_loss: 1.9377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12791e85b50>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load ../answers/callbacks.py\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "callbacks = [EarlyStopping(), ModelCheckpoint(model_path, save_best_only=True)]\n",
    "callbacks = [ModelCheckpoint(model_path, save_best_only=True)]\n",
    "\n",
    "\n",
    "fashion_model = make_fashion_mnist_model()\n",
    "fashion_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "fashion_model.fit(\n",
    "    train_iterator,\n",
    "    validation_data=valid_iterator,\n",
    "    steps_per_epoch=10,\n",
    "    epochs=4,\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard\n",
    "\n",
    "TensorBoard helps you visualize what's happening during training.\n",
    "For instance, it can visualize losses during training, weights of your layers, embedding and the computational graph.\n",
    "TensorBoard makes it easier to understand, debug, and optimize your model.\n",
    "\n",
    "<img src=\"../images/keras_advanced/tensorboard.png\" alt=\"flow_from\" style=\"width: 600px;\"/>\n",
    "\n",
    "For Keras it's just another built-in callback.\n",
    "Using the callback writes files to a directory that can be visualized by a separate process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TensorBoard in module keras.callbacks:\n",
      "\n",
      "class TensorBoard(Callback, keras.utils.version_utils.TensorBoardVersionSelector)\n",
      " |  TensorBoard(*args, **kwargs)\n",
      " |  \n",
      " |  Enable visualizations for TensorBoard.\n",
      " |  \n",
      " |  TensorBoard is a visualization tool provided with TensorFlow.\n",
      " |  \n",
      " |  This callback logs events for TensorBoard, including:\n",
      " |  \n",
      " |  * Metrics summary plots\n",
      " |  * Training graph visualization\n",
      " |  * Activation histograms\n",
      " |  * Sampled profiling\n",
      " |  \n",
      " |  When used in `Model.evaluate`, in addition to epoch summaries, there will be\n",
      " |  a summary that records evaluation metrics vs `Model.optimizer.iterations`\n",
      " |  written. The metric names will be prepended with `evaluation`, with\n",
      " |  `Model.optimizer.iterations` being the step in the visualized TensorBoard.\n",
      " |  \n",
      " |  If you have installed TensorFlow with pip, you should be able\n",
      " |  to launch TensorBoard from the command line:\n",
      " |  \n",
      " |  ```\n",
      " |  tensorboard --logdir=path_to_your_logs\n",
      " |  ```\n",
      " |  \n",
      " |  You can find more information about TensorBoard\n",
      " |  [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).\n",
      " |  \n",
      " |  Args:\n",
      " |      log_dir: the path of the directory where to save the log files to be\n",
      " |        parsed by TensorBoard. e.g. log_dir = os.path.join(working_dir, 'logs')\n",
      " |        This directory should not be reused by any other callbacks.\n",
      " |      histogram_freq: frequency (in epochs) at which to compute activation and\n",
      " |        weight histograms for the layers of the model. If set to 0, histograms\n",
      " |        won't be computed. Validation data (or split) must be specified for\n",
      " |        histogram visualizations.\n",
      " |      write_graph: whether to visualize the graph in TensorBoard. The log file\n",
      " |        can become quite large when write_graph is set to True.\n",
      " |      write_images: whether to write model weights to visualize as image in\n",
      " |        TensorBoard.\n",
      " |      write_steps_per_second: whether to log the training steps per second into\n",
      " |        Tensorboard. This supports both epoch and batch frequency logging.\n",
      " |      update_freq: `'batch'` or `'epoch'` or integer. When using `'batch'`,\n",
      " |        writes the losses and metrics to TensorBoard after each batch. The same\n",
      " |        applies for `'epoch'`. If using an integer, let's say `1000`, the\n",
      " |        callback will write the metrics and losses to TensorBoard every 1000\n",
      " |        batches. Note that writing too frequently to TensorBoard can slow down\n",
      " |        your training.\n",
      " |      profile_batch: Profile the batch(es) to sample compute characteristics.\n",
      " |        profile_batch must be a non-negative integer or a tuple of integers.\n",
      " |        A pair of positive integers signify a range of batches to profile.\n",
      " |        By default, profiling is disabled.\n",
      " |      embeddings_freq: frequency (in epochs) at which embedding layers will be\n",
      " |        visualized. If set to 0, embeddings won't be visualized.\n",
      " |      embeddings_metadata: Dictionary which maps embedding layer names to the\n",
      " |        filename of a file in which to save metadata for the embedding layer.\n",
      " |        In case the same metadata file is to be\n",
      " |        used for all embedding layers, a single filename can be passed.\n",
      " |  \n",
      " |  Examples:\n",
      " |  \n",
      " |  Basic usage:\n",
      " |  \n",
      " |  ```python\n",
      " |  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
      " |  model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])\n",
      " |  # Then run the tensorboard command to view the visualizations.\n",
      " |  ```\n",
      " |  \n",
      " |  Custom batch-level summaries in a subclassed Model:\n",
      " |  \n",
      " |  ```python\n",
      " |  class MyModel(tf.keras.Model):\n",
      " |  \n",
      " |    def build(self, _):\n",
      " |      self.dense = tf.keras.layers.Dense(10)\n",
      " |  \n",
      " |    def call(self, x):\n",
      " |      outputs = self.dense(x)\n",
      " |      tf.summary.histogram('outputs', outputs)\n",
      " |      return outputs\n",
      " |  \n",
      " |  model = MyModel()\n",
      " |  model.compile('sgd', 'mse')\n",
      " |  \n",
      " |  # Make sure to set `update_freq=N` to log a batch-level summary every N batches.\n",
      " |  # In addition to any `tf.summary` contained in `Model.call`, metrics added in\n",
      " |  # `Model.compile` will be logged every N batches.\n",
      " |  tb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n",
      " |  model.fit(x_train, y_train, callbacks=[tb_callback])\n",
      " |  ```\n",
      " |  \n",
      " |  Custom batch-level summaries in a Functional API Model:\n",
      " |  \n",
      " |  ```python\n",
      " |  def my_summary(x):\n",
      " |    tf.summary.histogram('x', x)\n",
      " |    return x\n",
      " |  \n",
      " |  inputs = tf.keras.Input(10)\n",
      " |  x = tf.keras.layers.Dense(10)(inputs)\n",
      " |  outputs = tf.keras.layers.Lambda(my_summary)(x)\n",
      " |  model = tf.keras.Model(inputs, outputs)\n",
      " |  model.compile('sgd', 'mse')\n",
      " |  \n",
      " |  # Make sure to set `update_freq=N` to log a batch-level summary every N batches.\n",
      " |  # In addition to any `tf.summary` contained in `Model.call`, metrics added in\n",
      " |  # `Model.compile` will be logged every N batches.\n",
      " |  tb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n",
      " |  model.fit(x_train, y_train, callbacks=[tb_callback])\n",
      " |  ```\n",
      " |  \n",
      " |  Profiling:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Profile a single batch, e.g. the 5th batch.\n",
      " |  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
      " |      log_dir='./logs', profile_batch=5)\n",
      " |  model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])\n",
      " |  \n",
      " |  # Profile a range of batches, e.g. from 10 to 20.\n",
      " |  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
      " |      log_dir='./logs', profile_batch=(10,20))\n",
      " |  model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TensorBoard\n",
      " |      Callback\n",
      " |      keras.utils.version_utils.TensorBoardVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, write_steps_per_second=False, update_freq='epoch', profile_batch=0, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  on_epoch_begin(self, epoch, logs=None)\n",
      " |      Called at the start of an epoch.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run. This function should only\n",
      " |      be called during TRAIN mode.\n",
      " |      \n",
      " |      Args:\n",
      " |          epoch: Integer, index of epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_epoch_end(self, epoch, logs=None)\n",
      " |      Runs metrics and histogram summaries at epoch end.\n",
      " |  \n",
      " |  on_test_begin(self, logs=None)\n",
      " |      Called at the beginning of evaluation or validation.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_test_end(self, logs=None)\n",
      " |      Called at the end of evaluation or validation.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently the output of the last call to\n",
      " |            `on_test_batch_end()` is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_train_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a training batch in `fit` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_train_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a training batch in `fit` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  on_train_begin(self, logs=None)\n",
      " |      Called at the beginning of training.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_train_end(self, logs=None)\n",
      " |      Called at the end of training.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently the output of the last call to `on_epoch_end()`\n",
      " |            is passed to this argument for this method but that may change in\n",
      " |            the future.\n",
      " |  \n",
      " |  set_model(self, model)\n",
      " |      Sets Keras model and writes graph if specified.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Callback:\n",
      " |  \n",
      " |  on_batch_begin(self, batch, logs=None)\n",
      " |      A backwards compatibility alias for `on_train_batch_begin`.\n",
      " |  \n",
      " |  on_batch_end(self, batch, logs=None)\n",
      " |      A backwards compatibility alias for `on_train_batch_end`.\n",
      " |  \n",
      " |  on_predict_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a batch in `predict` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_predict_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a batch in `predict` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  on_predict_begin(self, logs=None)\n",
      " |      Called at the beginning of prediction.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_predict_end(self, logs=None)\n",
      " |      Called at the end of prediction.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_test_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a batch in `evaluate` methods.\n",
      " |      \n",
      " |      Also called at the beginning of a validation batch in the `fit`\n",
      " |      methods, if validation data is provided.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_test_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a batch in `evaluate` methods.\n",
      " |      \n",
      " |      Also called at the end of a validation batch in the `fit`\n",
      " |      methods, if validation data is provided.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  set_params(self, params)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Callback:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.utils.version_utils.TensorBoardVersionSelector:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tensorflow.keras.callbacks.TensorBoard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Exercise: TensorBoard\n",
    "\n",
    "Add the TensorBoard call back to the training of the Fashion MNIST model, set:\n",
    "\n",
    "> - `log_dir` to the variable `run_dir` defined below\n",
    "> - Write the graph and gradients.\n",
    "> - Use the data set `(x_train, y_train), (x_test, y_test)` as defined below and train for 10 runs.\n",
    "\n",
    "Start training, open a terminal, make sure you're in the root folder of this project and run:\n",
    "> \n",
    "> ```\n",
    "> $ tensorboard --logdir=output/fashion_mnist\n",
    "> ```\n",
    ">\n",
    "Start multiple runs but make sure to execute the cell with `run_dir`.\n",
    "> - What happens with the losses of multiple runs?\n",
    "> - With the graphs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (x_train, y_train),\n",
    "    (x_test, y_test),\n",
    ") = tensorflow.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:10000, :, :, np.newaxis]\n",
    "x_test = x_test[:1000, :, :, np.newaxis]\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train[:10000])\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\output\\\\fashion_mnist\\\\run_1639666766.245051'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_dir = os.path.join(model_dir, f\"run_{time.time()}\")\n",
    "run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "313/313 [==============================] - 7s 20ms/step - loss: 3.2118 - val_loss: 0.8411\n",
      "Epoch 2/2\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.8861 - val_loss: 0.6726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x127a1c2ba00>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load ../answers/tensorboard.py\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "callbacks = [TensorBoard(run_dir, write_graph=True)]\n",
    "\n",
    "\n",
    "fashion_model = make_fashion_mnist_model()\n",
    "fashion_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "fashion_model.fit(\n",
    "    x_train, y_train, epochs=2, validation_data=(x_test, y_test), callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom callbacks\n",
    "\n",
    "\n",
    "If the available callbacks don't fit your use case, it's easy to define your own.\n",
    "`LambdaCallback` can be used for simple functionality, but you can also subclass the `Callback` class.\n",
    "\n",
    "As mentioned earlier, there are six moments when a callback can be executed: at starts and/or stops of training, epochs and/or batches.\n",
    "These correspond with the arguments or methods:\n",
    "\n",
    "- `on_epoch_begin`\n",
    "- `on_epoch_end`\n",
    "- `on_batch_begin`\n",
    "- `on_batch_end`\n",
    "- `on_train_begin`\n",
    "- `on_train_end`\n",
    "\n",
    "\n",
    "If we'd want to emojify our training logs a bit, we could abuse the `LambdaCallback`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥\n",
      "Epoch 1/2\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 3.1822\n",
      "Epoch 2/2\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.8539\n",
      "🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖🤖\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1278fa2b4c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "\n",
    "def on_train_begin(_):\n",
    "    print(\"🔥\" * 30)\n",
    "\n",
    "\n",
    "def on_train_end(_):\n",
    "    print(\"🤖\" * 30)\n",
    "\n",
    "\n",
    "emoji_callback = LambdaCallback(\n",
    "    on_train_begin=on_train_begin, on_train_end=on_train_end\n",
    ")\n",
    "\n",
    "fashion_model = make_fashion_mnist_model()\n",
    "fashion_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "fashion_model.fit(x_train, y_train, epochs=2, callbacks=[emoji_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex logic should be captured in a subclass of the `Callback` class.\n",
    "It has six methods to overwrite and by default we get access to a few attributes: the model, trainings parameters and validation data.\n",
    "You can inspect the contents of the `tensorflow.keras.callbacks.Callback` class by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??tensorflow.keras.callbacks.Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Exercise: Custom callback\n",
    "> - Write a callback that prints the standard deviation of the weights in the last layer at the end of each epoch.\n",
    "> - Train a new model again and observe how the loss changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 18.6526\n",
      "Weight std of last layer: 3.61E-03\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 18.0608 - val_loss: 1.3869\n",
      "Epoch 2/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 2.3137\n",
      "Weight std of last layer: 5.62E-03\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 2.3091 - val_loss: 1.3110\n",
      "Epoch 3/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 1.7079\n",
      "Weight std of last layer: 7.49E-03\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 1.7053 - val_loss: 1.1827\n",
      "Epoch 4/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 1.4712\n",
      "Weight std of last layer: 1.14E-02\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 1.4739 - val_loss: 1.0825\n",
      "Epoch 5/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 1.2905\n",
      "Weight std of last layer: 1.53E-02\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 1.3020 - val_loss: 0.9962\n",
      "Epoch 6/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 1.1824\n",
      "Weight std of last layer: 1.92E-02\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 1.1807 - val_loss: 0.8883\n",
      "Epoch 7/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 1.0544\n",
      "Weight std of last layer: 2.27E-02\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 1.0524 - val_loss: 0.8564\n",
      "Epoch 8/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.9348\n",
      "Weight std of last layer: 2.58E-02\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.9480 - val_loss: 0.7676\n",
      "Epoch 9/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.9166\n",
      "Weight std of last layer: 2.90E-02\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.9259 - val_loss: 0.7873\n",
      "Epoch 10/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.8904\n",
      "Weight std of last layer: 3.12E-02\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.8962 - val_loss: 0.7327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1279132f160>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load ../answers/custom_callback.py\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "class WeightStdCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super(WeightStdCallback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        print(\n",
    "            f\"\\nWeight std of last layer: {self.model.weights[-1].numpy().std():1.2E}\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "\n",
    "fashion_model = make_fashion_mnist_model()\n",
    "fashion_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "fashion_model.fit(\n",
    "    x_train[:1000, :, :, :],\n",
    "    y_train[:1000],\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[WeightStdCallback()],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This section showed how callbacks can be used to save & monitor your models.\n",
    "If you need a visualization tool during training, TensorBoard has easy integration with Keras.\n",
    "For custom functionality you can write your own callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"../output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
