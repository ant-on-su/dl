{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/custom.css\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks for Sentiment Classification\n",
    "\n",
    "\n",
    "Feedforward networks learn their parameters once and have a fixed state, so they cannot take context in the input data into account.\n",
    "\n",
    "Recurrent neural networks (RNNs) also learn their parameters once, but keep a state depending on the sequence they have seemed so far.\n",
    "\n",
    "This makes RNNs well suited for problems with sequences, like converting speech to text: translation of a word can be helped by knowing the words that came before.\n",
    "\n",
    "![footer_logo](../images/logo.png)\n",
    "\n",
    "## Goal\n",
    "\n",
    "In this exercise we'll apply a RNN for sentiment classification.\n",
    "We'll get some reviews from movies and try to classify if they have a positive or negative sentiment.\n",
    "\n",
    "## Program\n",
    "\n",
    "- [Introducing the dataset]()\n",
    "- [Preprocessing the data]()\n",
    "- [The model]()\n",
    "- [Extension exercises]()\n",
    "    - [Compare against a baseline model]()\n",
    "    - [Minimum viable network]()\n",
    "    - [Visualising the embeddings]()\n",
    "    - [Transfer learning (Glove)]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data\n",
    "\n",
    "Like many other libraries, `keras` includes some standard datasets to play around with.\n",
    "We'll use the IMDB dataset. This section shows what this dataset contains.\n",
    "\n",
    "From the [website](https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification) (emphasis ours): \n",
    "\n",
    "> \"Dataset of __25,000 movies reviews from IMDB, labeled by sentiment (positive/negative)__. Reviews have been preprocessed, and __each review is encoded as a sequence of word indexes__ (integers). For convenience, __words are indexed by overall frequency__ in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".\n",
    ">\n",
    "> As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n",
    "\n",
    "\n",
    "We'll load reviews with only the 20,000 most frequent words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n",
      "17473536/17464789 [==============================] - 2s 0us/step\n",
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "NUM_WORDS = 20000\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=NUM_WORDS)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "print(len(x_train), \"train sequences\")\n",
    "print(len(x_test), \"test sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x_train` and `x_test` are `numpy.ndarray`'s containing list of sequences.\n",
    "\n",
    "A few examples are show below: the samples don't have the same length and are encoded by integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may be a valid way to represent text for machines, but it's not really usefull for humans.\n",
    "Let's try to get the original text back.\n",
    "\n",
    "The `imdb` module ships with a function `get_word_index()` to decode the integers to words, but we'll have to do some extra work: there are some special words for that are not the word index.\n",
    "See the arguments `start_char`, `oov_char` and `index_from` of the function `imdb.load_data()` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "INDEX_FROM = 3  # First actual word.\n",
    "\n",
    "word_index = imdb.get_word_index()\n",
    "word_to_index = {k: (v + INDEX_FROM) for k, v in word_index.items()}\n",
    "# Add special words.\n",
    "word_to_index[\"<PAD>\"] = 0  # Padding\n",
    "word_to_index[\"<START>\"] = 1  # Starting of sequence\n",
    "word_to_index[\"<UNK>\"] = 2  # Unknown word\n",
    "\n",
    "index_to_word = {v: k for k, v in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our dictionary `index_to_word` we can display the original reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> worst mistake of my life br br i picked this movie up at target for 5 because i figured hey it's sandler i can get some cheap laughs i was wrong completely wrong mid way through the film all three of my friends were asleep and i was still suffering worst plot worst script worst movie i have ever seen i wanted to hit my head up against a wall for an hour then i'd stop and you know why because it felt damn good upon bashing my head in i stuck that damn movie in the <UNK> and watched it burn and that felt better than anything else i've ever done it took american psycho army of darkness and kill bill just to get over that crap i hate you sandler for actually going through with this and ruining a whole day of my life\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I_SHOW = 4\n",
    "\n",
    "\" \".join([index_to_word[w] for w in x_train[I_SHOW]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x_train[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Exercise \n",
    "\n",
    "Play around with `I_SHOW` and read some other reviews!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous section showed that the text was encoded by integers, but we need to do some more processing: `keras` needs all sequences (/reviews) to be of equal length.\n",
    "\n",
    "We can choose to pad all sequences to the longest length, or we can choose a maximum review length and cut longer reviews.\n",
    "We'll cut reviews after `MAXLEN=80` words and pad them if needed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train (25000, 250)\n",
      "Size of X_test (25000, 250)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "MAXLEN = 250\n",
    "\n",
    "X_train = sequence.pad_sequences(x_train, maxlen=MAXLEN)\n",
    "X_test = sequence.pad_sequences(x_test, maxlen=MAXLEN)\n",
    "\n",
    "print(\"Size of X_train\", X_train.shape)\n",
    "print(\"Size of X_test\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this a valid threshold?\n",
    "\n",
    "The figure below shows that we'll be cutting most texts and padding only some.\n",
    "However, this can be fine: most of the sentiment could be in the first 80 words.\n",
    "If we find out that it's not enough, we'll come back and increase the text length!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2760d786520>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "lengths = [len(s) for s in x_train]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.kdeplot(lengths, cumulative=True, label=\"x_train\", ax=ax)\n",
    "ax.plot((MAXLEN, MAXLEN), ax.get_ylim(), \"--k\")\n",
    "ax.set_xlabel(\"Sequence lengths [# words]\")\n",
    "ax.set_ylabel(\"Cumulative fraction\")\n",
    "ax.set_title(\"Occurence of sequence lengths in reviews\")\n",
    "ax.legend([\"x_train\", \"Max length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now done with the preprocessing!\n",
    "In our training set we have 25000 reviews of 80 words (some of the padded).\n",
    "All words are encoded by integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAXLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train: (25000, 250)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   11,     2,    21,    29,     9,  2841,    23,     4,  1010,\n",
       "           2,   793,     6, 13699,  1386,  1830,    10,    10,   246,\n",
       "          50,     9,     6,  2750,  1944,   746,    90,    29, 16376,\n",
       "           8,   124,     4,   882,     4,   882,   496,    27,     2,\n",
       "        2213,   537,   121,   127,  1219,   130,     5,    29,   494,\n",
       "           8,   124,     4,   882,   496,     4,   341,     7,    27,\n",
       "         846,    10,    10,    29,     9,  1906,     8,    97,     6,\n",
       "         236, 11120,  1311,     8,     4,     2,     7,    31,     7,\n",
       "           2,    91,     2,  3987,    70,     4,   882,    30,   579,\n",
       "          42,     9,    12,    32,    11,   537,    10,    10,    11,\n",
       "          14,    65,    44,   537,    75, 11876,  1775,  3353, 12716,\n",
       "        1846,     4, 11286,     7,   154,     5,     4,   518,    53,\n",
       "       13243, 11286,     7,  3211,   882,    11,   399,    38,    75,\n",
       "         257,  3807,    19, 18223,    17,    29,   456,     4,    65,\n",
       "           7,    27,   205,   113,    10,    10,     2,     4,     2,\n",
       "       10359,     9,   242,     4,    91,  1202, 11377,     5,  2070,\n",
       "         307,    22,     7,  5168,   126,    93,    40, 18223,    13,\n",
       "         188,  1076,  3222,    19,     4, 13465,     7,  2348,   537,\n",
       "          23,    53,   537,    21,    82,    40, 18223,    13,     2,\n",
       "          14,   280,    13,   219,     4,     2,   431,   758,   859,\n",
       "           4,   953,  1052, 12283,     7,  5991,     5,    94,    40,\n",
       "          25,   238,    60,     2,     4, 15812,   804,     2,     7,\n",
       "           4,  9941,   132,     8,    67,     6,    22,    15,     9,\n",
       "         283,     8,  5168,    14,    31,     9,   242,   955,    48,\n",
       "          25,   279,     2,    23,    12,  1685,   195,    25,   238,\n",
       "          60,   796, 13713,     4,   671,     7,  2804,     5,     4,\n",
       "         559,   154,   888,     7,   726,    50,    26,    49,  7008,\n",
       "          15,   566,    30,   579,    21,    64,  2574])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Size of X_train:\", X_train.shape)\n",
    "\n",
    "X_train[3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
       "         14,   47,    8,   30,   31,    7,    4,  249,  108,    7,    4,\n",
       "       5974,   54,   61,  369,   13,   71,  149,   14,   22,  112,    4,\n",
       "       2401,  311,   12,   16, 3711,   33,   75,   43, 1829,  296,    4,\n",
       "         86,  320,   35,  534,   19,  263, 4821, 1301,    4, 1873,   33,\n",
       "         89,   78,   12,   66,   16,    4,  360,    7,    4,   58,  316,\n",
       "        334,   11,    4, 1716,   43,  645,  662,    8,  257,   85, 1200,\n",
       "         42, 1228, 2578,   83,   68, 3912,   15,   36,  165, 1539,  278,\n",
       "         36,   69,    2,  780,    8,  106,   14, 6905, 1338,   18,    6,\n",
       "         22,   12,  215,   28,  610,   40,    6,   87,  326,   23, 2300,\n",
       "         21,   23,   22,   12,  272,   40,   57,   31,   11,    4,   22,\n",
       "         47,    6, 2307,   51,    9,  170,   23,  595,  116,  595, 1352,\n",
       "         13,  191,   79,  638,   89,    2,   14,    9,    8,  106,  607,\n",
       "        624,   35,  534,    6,  227,    7,  129,  113])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're done with all the data manipulation, what is our neural network going to look like?\n",
    "\n",
    "Our initial model will consist of three layers: an embedding layer, a recurrent layer and a dense layer.\n",
    "The embedding layer learns the relations between words, the recurrent layer learns what the document is about and the dense layer translates that to sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Embedding layer\n",
    "\n",
    "The embedding layer will embed our original word vectors in a dense, lower-dimensional space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings can capture __semantic information__ about words and their relationships to one another. \n",
    "Certain directions in the vector space embed certain semantic relationships such as male-femal, verb-tense and country-capital relationships between words.\n",
    "\n",
    "<img src=\"../images/nlp/linear-relationships.png\" alt=\"Drawing\" style=\"width: 90%;\"/>\n",
    "\n",
    "> Source: https://www.tensorflow.org/tutorials/word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build an embedding layer in Keras using `keras.layers.Embedding`. Keras can learn this layer for you, but you can also pretrained embeddings generated by others.\n",
    "More on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Recurrent layer\n",
    "\n",
    "__Recurrent Neural Nets__ naturally deal with word order because they can go over a __sequence__ of words and keep a __memory__ of the information that has been calculated so far.\n",
    "\n",
    "This could help when trying to assign sentiment to sentences, as shown in the figure below.\n",
    "A word can trigger a sentiment that carries on for one or multiple sentences.\n",
    "\n",
    "<img src=\"../images/nlp/sentiment-neuron.gif\" style=\"width: 75%;\"/>\n",
    "\n",
    "\n",
    "> Source: [Unsupervised Sentiment Neuron](https://blog.openai.com/unsupervised-sentiment-neuron/)\n",
    "\n",
    "If we'd be interested in __understanding a document__ like in the previous example, we could use the following architecture:\n",
    "\n",
    "<img src=\"../images/nlp/rnn-architecture.png\" style=\"width: 75%;\"/>\n",
    "\n",
    "> Source: [Goodfellow, 2016]\n",
    "\n",
    "The left side of the figure shows a short-hand of the neural network, the right side shows the unrolled version.\n",
    "\n",
    "At each time-step, the input is the output of the previous time-step $\\mathbf{h}^{(t-1)}$ and a new input word vector $\\mathbf{x}^{(t)}$.\n",
    "\n",
    "Over time we adjust our idea of the document $\\mathbf{h}^{(t)}$ until we've seen all words in the document.\n",
    "\n",
    "This is illustrated in the figure below: we get a new word vector at each time-step and __carry over a score__. The final score $\\mathbf{h}^{(T)}$ represents what the neural network has learned about the document after having seen every word. We will use the final score to detect the sentiments of the text.\n",
    "\n",
    "![center](../images/rnn/rnn_many_to_one.jpeg)\n",
    "\n",
    "We'll use a specific kind of recurrent layer: a LSTM.\n",
    "The Long Short Term Memory neuron are able to learn long-term dependencies and often perform better than standard RNNs.\n",
    "\n",
    "![center three_quarters](../images/lstm/LSTM_overview.png)\n",
    "Read [this blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) if you'd like more info.\n",
    "\n",
    "The LSTM layer can be found in `keras.layers.LSTM`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Dense layer\n",
    "\n",
    "The first layer learns a good representation of words, the second learns to combine words in a single idea, and the final layer turns this idea into a classification.\n",
    "\n",
    "We will use a simple dense layer from `keras.layers.Dense` that transforms the idea vectors into a 0 or 1.\n",
    "The layer will consist of a single neuron that takes all connections and outputs 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we now how the architecture looks like and we have our data in `X_train` and `X_test`, it's time to build a model.\n",
    "\n",
    "### <mark> Exercise: LSTM for sentiment classification\n",
    "    \n",
    "<img src=\"../images/nlp/m_lstm_sentiment.png\" width=\"500\"/>\n",
    "\n",
    "> * Build a sequential model with three layers: embedding, LSTM and dense layers. \n",
    ">     * Don't make the embedding layer *larger than* 200 units. Use `NUM_WORDS` as the vocabulary size.\n",
    ">     * Use *at most* 256 LSTM units. Play around with parameters `dropout` and `recurrent_dropout`.\n",
    "> * Compile the model with `'binary_crossentropy'` as the loss and use `'accuracy'` as validation metric.\n",
    "> * Add callbacks to the fitting: use `keras.callbacks.ModelCheckpoint()` and `keras.callbacks.EarlyStopping()`.\n",
    "> * Reasonable test scores are 0.42 for the binary cross-entropy and and 0.81 for the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "23/98 [======>.......................] - ETA: 2:49 - loss: 0.6884 - accuracy: 0.5533"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10468/4210541616.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Compile and train.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gdd-dl\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gdd-dl\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gdd-dl\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gdd-dl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gdd-dl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gdd-dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gdd-dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gdd-dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gdd-dl\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %load ../answers/sentiment_lstm.py\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "# Make our model.\n",
    "model = Sequential()\n",
    "model.add(Embedding(NUM_WORDS, 32))  # size of the vector; i.e. the number of nodes in the shallow word embedding network\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Callbacks.\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    filepath=\"../output/imdb_lstm.h5\", verbose=1, save_best_only=True\n",
    ")\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=0, patience=2, verbose=0, mode=\"auto\"\n",
    ")\n",
    "\n",
    "# Compile and train.\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=256,\n",
    "    epochs=2,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[checkpoint, early_stopping],\n",
    ")\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=64)\n",
    "\n",
    "print(\"Test score:\", score)\n",
    "print(\"Test accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you reached the benchmarks, you've succesfully trained a recurrent neural network for text classification!\n",
    "\n",
    "The next section gives some pointers what to do next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Extension exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've only touched the surface on applying RNNs to text.\n",
    "This section contains some more exercises to deepen your understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Exercise: Baseline\n",
    "\n",
    "This dataset is small, so might not really benefit from the complexity from deep learning.\n",
    "> Use [`sklearn`](http://scikit-learn.org/stable/) to create a baseline: create a `Pipeline` using the `TfidfVectorizer()` and `BernoulliNB()` \n",
    "> What's your best score?\n",
    "\n",
    "Hint:\n",
    "> Use `X_train_translated` and `X_test_translated` from below; `TfidfVectorizer()` works better with real strings than integers.\n",
    "> You can still use `y_train` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indices to text.\n",
    "X_train_translated = [\" \".join(index_to_word[w] for w in s) for s in x_train]\n",
    "X_test_translated = [\" \".join(index_to_word[w] for w in s) for s in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8466, 0.85  , 0.8592, 0.8476, 0.8524])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load ../answers/sentiment_sklearn.py\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "pipeline = make_pipeline(text.TfidfVectorizer(), BernoulliNB())\n",
    "model_selection.cross_val_score(\n",
    "    pipeline, X_train_translated, y_train, cv=5, scoring=\"accuracy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Exercise: Minimum Viable Network\n",
    "\n",
    "You probably don't need a big network for this small dataset: there's not enough data to learn really complex relations.\n",
    ">What's the smallest network you still get good results with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 367s 935ms/step - loss: 0.5042 - accuracy: 0.7365 - val_loss: 0.3318 - val_accuracy: 0.8631\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 444s 1s/step - loss: 0.2538 - accuracy: 0.9002 - val_loss: 0.3054 - val_accuracy: 0.8733\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 441s 1s/step - loss: 0.1657 - accuracy: 0.9416 - val_loss: 0.3524 - val_accuracy: 0.8575\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 453s 1s/step - loss: 0.1282 - accuracy: 0.9550 - val_loss: 0.3753 - val_accuracy: 0.8576\n",
      "391/391 [==============================] - 60s 153ms/step - loss: 0.3753 - accuracy: 0.8576\n",
      "Test score: 0.3752788305282593\n",
      "Test accuracy: 0.8575999736785889\n"
     ]
    }
   ],
   "source": [
    "# %load ../answers/sentiment_mvn.py\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "# Make our model.\n",
    "mvm = Sequential()\n",
    "mvm.add(Embedding(NUM_WORDS, 30))\n",
    "mvm.add(LSTM(128, dropout=0.1, recurrent_dropout=0.1))\n",
    "mvm.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile and train.\n",
    "mvm.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "mvm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "score, acc = mvm.evaluate(X_test, y_test, batch_size=64)\n",
    "\n",
    "print(\"Test score:\", score)\n",
    "print(\"Test accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Exercise: Visualizing Embeddings\n",
    "\n",
    "We explained previously that the embeddings could learn relations between words.\n",
    "    \n",
    "However, we didn't prove this for this solution: we just provided an architecture for the network and told the network to learn sentiment.\n",
    "    \n",
    "This means that it didn't necessarily use the embedding to learn a representation that makes sense to us: everything was conditioned on sentiment classfication.\n",
    "\n",
    ">Visualize the embeddings: are they any good?\n",
    "> * Get the weights from the right layer:\n",
    "    * See the attribute `.layers` of the network.\n",
    "    * Use the method `.get_weights()` of the layer.\n",
    "> * Use [TSNE](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) to map the weights into a 2D representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../answers/sentiment_tsne.py\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "embedding_weights = model.layers[0].get_weights()[0]\n",
    "embedding_2d = TSNE().fit_transform(embedding_weights[:1000, :])\n",
    "plt.plot(embedding_2d[:, 0], embedding_2d[:, 1], \"o\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Exercise: Transfer Learning\n",
    "\n",
    "Instead of training the embeddings, you can use word embeddings pretrained on a large corpus.\n",
    "\n",
    "This allows you to leverage complex relations learned from large corpora on your smaller datasets.\n",
    ">\n",
    "> - Read [this Keras blog](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html)\n",
    "> - Rerun your model using word embeddings from GloVe. Note that not all words may be present, so you'll have to do some preprocessing.\n",
    "\n",
    "Does it improve your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Summary\n",
    "\n",
    "In this notebook we used RNNs to sequentially process word embeddings, so that we could perform sentiment classification on movie reviews."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
